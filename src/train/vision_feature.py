
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import seaborn as sns
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import os
import sys
from torchvision import transforms
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, WeightedRandomSampler
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from tqdm import tqdm
import time
import os
import sys
from torchvision import transforms
from torch.cuda.amp import autocast, GradScaler
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import pdist, squareform
import seaborn as sns
model_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../model"))
sys.path.append(model_path)
from resnet import ResNet34
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score
from scipy.cluster.hierarchy import dendrogram, linkage
import seaborn as sns
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

# 1. æ•°æ®åŠ è½½è®¾ç½®
def load_data(data_path):
    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor()
    ])
    dataset = ImageFolder(data_path, transform=transform)
    loader = DataLoader(dataset, batch_size=128, shuffle=False)
    return dataset, loader

# 2. ç‰¹å¾æå–å‡½æ•°ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
def extract_features(model, dataloader, class_idx, device):
    features = []
    
    with torch.no_grad():
        for images, labels in dataloader:
            images = images.to(device)
            labels = labels.to(device)
            
            mask = (labels == class_idx)
            if torch.any(mask):
                target_images = images[mask]
                _, features_batch = model.penultimate_forward(target_images)
                pooled = torch.mean(features_batch, dim=(2, 3))
                features.append(pooled.cpu().numpy())
    
    return np.concatenate(features, axis=0) if features else np.array([])

# 3. å¤šèšç±»éªŒè¯å¯è§†åŒ–
def visualize_multiple_clusters(features, class_name):
    if len(features) == 0:
        print(f"é”™è¯¯ï¼š{class_name}ç±»åˆ«æ²¡æœ‰ç‰¹å¾æ•°æ®")
        return None
    
    # éšæœºé‡‡æ ·300ä¸ªç‚¹ä»¥ä¾¿å¯è§†åŒ–æ›´æ¸…æ™°ï¼ˆå½“æ•°æ®é‡å¤§æ—¶ï¼‰
    if len(features) > 1500:
        np.random.seed(42)
        indices = np.random.choice(len(features), 1500, replace=False)
        features = features[indices]
    
    plt.figure(figsize=(18, 16))
    
    # ä¸»æˆåˆ†åˆ†ææŠ•å½±
    plt.subplot(2, 2, 1)
    pca = PCA(n_components=2)
    pca_results = pca.fit_transform(features)
    
    # å°è¯•èšç±»ï¼ˆå‡è®¾3-5ä¸ªé›†ç¾¤ï¼‰
    n_clusters = min(7, max(2, len(features)//100))  # åŠ¨æ€ç¡®å®šèšç±»æ•°é‡
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(features)
    
    # è®¡ç®—è½®å»“ç³»æ•°
    try:
        silhouette = silhouette_score(features, cluster_labels)
    except ValueError:
        silhouette = -1.0  # å½“èšç±»æ•°ä¸åˆé€‚æ—¶
    
    scatter = plt.scatter(pca_results[:, 0], pca_results[:, 1], 
                          c=cluster_labels, cmap='tab10', s=25, alpha=0.8)
    plt.title(f'PCA Projection Clustering ({n_clusters} Subclasses)', fontsize=16)
    plt.xlabel('Principal Component 1', fontsize=14)
    plt.ylabel('Principal Component 2', fontsize=14)
    plt.legend(*scatter.legend_elements(), title="Subclasses")
    
    # t-SNEæŠ•å½±
    plt.subplot(2, 2, 2)
    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)
    tsne_results = tsne.fit_transform(features)
    plt.scatter(tsne_results[:, 0], tsne_results[:, 1], 
                c=cluster_labels, cmap='tab10', s=25, alpha=0.8)
    plt.title('t-SNE Projection Clustering', fontsize=16)
    plt.xlabel('t-SNE Dimension 1', fontsize=14)
    plt.ylabel('t-SNE Dimension 2', fontsize=14)    
    
    # å±‚æ¬¡èšç±»æ ‘çŠ¶å›¾
    plt.subplot(2, 2, 3)
    linked = linkage(features, 'ward')
    dendrogram(linked,
               orientation='top',
               truncate_mode='lastp',
               p=12,  # æ˜¾ç¤ºæœ€å12æ¬¡åˆå¹¶
               show_leaf_counts=True,
               leaf_rotation=90.,
               leaf_font_size=12.,
               show_contracted=True)
    plt.title('Hierarchical Clustering Dendrogram', fontsize=16)
    plt.xlabel('Sample Index', fontsize=14)
    plt.ylabel('Cluster Distance', fontsize=14)
    plt.axhline(y=linked[-4, 2], c='r', linestyle='--')
    
    # å­ç±»ç‰¹å¾æ¯”è¾ƒçƒ­åŠ›å›¾
    plt.subplot(2, 2, 4)
    cluster_means = []
    for i in range(n_clusters):
        cluster_features = features[cluster_labels == i]
        cluster_means.append(np.mean(cluster_features, axis=0))
    
    # åªæ˜¾ç¤ºæœ€æœ‰åŒºåˆ†åº¦çš„å‰50ä¸ªç‰¹å¾ç»´åº¦
    variances = np.var(cluster_means, axis=0)
    top_features = np.argsort(variances)[-50:][::-1]
    
    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
    heatmap_data = []
    for i in range(n_clusters):
        heatmap_data.append(cluster_means[i][top_features])
    
    sns.heatmap(np.array(heatmap_data).T, cmap='coolwarm', annot=False, linewidths=0.5)
    plt.title('Subclass Feature Differences', fontsize=16)
    plt.xlabel('Subclass ID', fontsize=14)
    plt.ylabel('Feature Dimensions', fontsize=14)
    plt.yticks([])  # éšè—yè½´åˆ»åº¦ï¼ˆç‰¹å¾ç»´åº¦å¤ªå¤šï¼‰
    
    plt.tight_layout()
    plt.suptitle(f'', fontsize=20, y=0.98)
    plt.savefig(f'{class_name}_clustering_visualization.png', dpi=300)
    plt.show()
    
    # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'-'*40}")
    print(f"{class_name}ç±»èšç±»éªŒè¯ç»“æœ")
    print(f"åˆ†ææ ·æœ¬æ•°: {len(features)}")
    print(f"æœ€ä¼˜åŒ–èšç±»æ•°: {n_clusters}")
    print(f"è½®å»“ç³»æ•°: {silhouette:.4f} (è¶Šé«˜è¶Šå¥½)")
    print(f"æ ‘çŠ¶å›¾åˆ†æ”¯æ•°: {np.sum(linked[-4:, 2] > linked[-5, 2])}ä¸ªæ˜¾è‘—åˆ†ç¦»ç¾¤")
    
    # åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¤šä¸ªå­ç±»
    if n_clusters > 1 and silhouette > 0.5:
        print("\nâœ… æ˜ç¡®è¯æ®è¡¨æ˜å­˜åœ¨å¤šä¸ªå­ç±»ç»“æ„")
        print("å­ç±»é—´ç‰¹å¾å·®å¼‚: æ˜¾è‘—ï¼ˆçƒ­åŠ›å›¾æ˜¾ç¤ºæ˜æ˜¾é¢œè‰²å˜åŒ–ï¼‰")
    elif n_clusters > 1:
        print("\nğŸŸ¡ å­˜åœ¨å­ç±»ç»“æ„ä½†åˆ†ç¦»ä¸æ˜æ˜¾")
        print("å»ºè®®: å°è¯•éçº¿æ€§èšç±»æ–¹æ³•å¦‚DBSCAN")
    else:
        print("\nâŒ æœªå‘ç°æ˜æ˜¾å­ç±»ç»“æ„")
        print("æ‰€æœ‰æ ·æœ¬åœ¨ç‰¹å¾ç©ºé—´ä¸­ç´§å¯†èšé›†")
    
    print(f"{'-'*40}\n")
    
    return cluster_labels

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    data_path = "dataset/ustc2016/final_data/train"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…è·¯å¾„
    dataset, train_loader = load_data(data_path)
    
    # åŠ è½½æ¨¡å‹ (ä»æ‚¨çš„ä»£ç ä¸­å¯¼å…¥ResNet34å’ŒResNetç±»)
    
    num_classes = len(dataset.classes)
    model = ResNet34(num_classes).to(device)
    model.load_state_dict(torch.load('best_model_ustc2016.pth', map_location=device))
    model.eval()
    
    # # é€‰æ‹©BitTorrentç±»
    # target_class_name = "BitTorrent"
    # target_class_idx = dataset.class_to_idx[target_class_name]
    for target_class_name in dataset.classes:
        target_class_idx = dataset.class_to_idx[target_class_name]
        
        print(f"æå– {target_class_name} ç±»åˆ«çš„ç‰¹å¾...")
        class_features = extract_features(model, train_loader, target_class_idx, device)
        
        if len(class_features) == 0:
            print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ° {target_class_name} ç±»åˆ«çš„æ ·æœ¬")
        else:
            print(f"æˆåŠŸæå– {len(class_features)} ä¸ª {target_class_name} æ ·æœ¬ç‰¹å¾")
            # æ‰§è¡Œå¤šèšç±»éªŒè¯
            cluster_labels = visualize_multiple_clusters(class_features, target_class_name)